name: "Deep Q-Network"

# training input layers
layer {
  name: "volumes_input_layer"
  type: "MemoryData"
  top: "volumes"
  top: "dummy_volumes"
  include {
    phase: TRAIN
  }
  memory_data_param {
    batch_size: 32
    channels: 4
    height: 100
    width: 1
  }
}
layer {
  name: "transform_input_layer"
  type: "MemoryData"
  top: "transform"
  top: "dummy_transform"
  include {
    phase: TRAIN
  }
  memory_data_param {
    batch_size: 32
    channels: 4
    height: 5 # 2 rotation values, 3 translate values
    width: 1
  }
}
layer {
  name: "target_input_layer"
  type: "MemoryData"
  top: "target"
  top: "dummy_target"
  include {
    phase: TRAIN
  }
  memory_data_param {
    batch_size: 32
    channels: 7
    height: 1
    width: 1
  }
}
layer {
  name: "filter_input_layer"
  type: "MemoryData"
  top: "filter"
  top: "dummy_filter"
  include {
    phase: TRAIN
  }
  memory_data_param {
    batch_size: 32
    channels: 7
    height: 1
    width: 1
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "dummy_volumes"
  bottom: "dummy_transform"
  bottom: "dummy_filter"
  bottom: "dummy_target"
  include {
    phase: TRAIN
  }
}
layer {
  name: "reshape_filter"
  type: "Reshape"
  bottom: "filter"
  top: "reshaped_filter"
  include {
    phase: TRAIN
  }
  reshape_param {
    shape {
      dim: 32
      dim: 7
    }
  }
}

# test and target input layers
layer {
  name: "volumes_input_layer"
  type: "MemoryData"
  top: "all_volumes"
  top: "dummy_volumes"
  include {
    phase: TEST
  }
  memory_data_param {
    batch_size: 32
    channels: 4
    height: 100
    width: 1
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "dummy_volumes"
  include {
    phase: TEST
  }
}


# reshape volumes input both train and test
layer {
  name: "reshape_volume"
  type: "Reshape"
  bottom: "volumes"
  top: "reshaped_volumes"
  include {
    phase: TRAIN
  }
  reshape_param {
    shape {
      dim: 32    # keep 32 batch size
      dim: 4    # keep 4 channels
      dim: 10   # set to 10, 10 grid
      dim: 10
    }
  }
}    
layer {
  name: "reshape_volume"
  type: "Reshape"
  bottom: "all_volumes"
  top: "reshaped_volumes"
  include {
    phase: TEST
  }
  reshape_param {
    shape {
      dim: 32    # keep 32 batch size
      dim: 4     # keep 4 channels
      dim: 10    # set to 10, 10 grid
      dim: 10
    }
  }
}



# conv layers
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "reshaped_volumes"
  top: "conv1"
  param {
    name: "conv1_w"
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  convolution_param {
    num_output: 32
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    #engine: CAFFE
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "reshaped_volumes"
  top: "conv1"
  param {
    name: "conv1_w"
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  convolution_param {
    num_output: 32
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    #engine: CAFFE
  }
}
layer {
  name: "conv1_relu_layer"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    name: "conv2_w"
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    #engine: CAFFE
  }
}
layer {
  name: "conv2_relu_layer"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.01
  }
}

layer {
  name: "reshape_conv2"
  type: "Reshape"
  bottom: "conv2"
  top: "conv2_reshaped"
#  include {
#    phase: TEST
#  }
  reshape_param {
    shape {
      dim: 0    # keep 32 batch size
      dim: 4    # 4 outputs to match the transforms
      dim: -1   # the remaining count
      dim: 1
    }
  }
}

# concat the convolutional output and the transform data
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv2_reshaped"
  bottom: "transform"
  top: "concat_conv_transform"
  concat_param {
    axis: 2
  }
}


# fully connected layers
layer {
  name: "ip1_layer"
  type: "InnerProduct"
  bottom: "concat_conv_transform"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ip1_relu_layer"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "ip2_layer"
  type: "InnerProduct"
  bottom: "ip1"
  top: "q_values"
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}

# filter layer leading to loss layer
layer {
  name: "eltwise_layer"
  type: "Eltwise"
  bottom: "q_values"
  bottom: "reshaped_filter"
  top: "filtered_q_values"
  include {
    phase: TRAIN
  }
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "filtered_q_values"
  bottom: "target"
  top: "loss"
  include {
    phase: TRAIN
  }
}
